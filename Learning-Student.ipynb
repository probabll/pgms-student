{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Start with your name(s) and student number(s)**\n",
    "\n",
    "Team:\n",
    "\n",
    "* FILL IN YOUR NAME (AND STUDENT NUMBER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "In this notebook we will learn about **parameter learning** in Probabilistic Graphical Models (PGMs). The main goal is to understand how we can estimate the parameters of a PGM from data.\n",
    "\n",
    "We will use Hidden Markov Models (HMMs) as a concrete example to illustrate different learning algorithms. HMMs are a special type of Bayesian network that model sequences, but the parameter estimation techniques we'll learn apply more broadly to PGMs.\n",
    "\n",
    "This is a high-level outline of the notebook, you will find exercises in most sections.\n",
    "\n",
    "1. **HMMs and Foward Sampling**: We introduce HMMs as an example model (briefly, just enough to understand the task)\n",
    "2. **Training with MLE**: We learn how to estimate parameters using Maximum Likelihood Estimation (MLE) via count-and-normalize\n",
    "3. **Testing**: We evaluate the trained model on test data using:\n",
    "   - Max-product inference from text and classification reports\n",
    "   - Reconstructing missing POS tags\n",
    "   - Computing marginal probabilities for fluency ranking\n",
    "4. **Semi-supervised Learning**: We learn parameters using a combination of labeled and unlabeled data\n",
    "\n",
    "**Table of Exercises**\n",
    "\n",
    "The exercises and the points they are worth are shown below:\n",
    "\n",
    "1. Exercise - Implement Forward Sampling [1pt]\n",
    "2. Exercise - Understanding MLE [0pt]\n",
    "3. Exercise - Implementing MLE [2pt]\n",
    "4. Exercise - Inferring POS-tags from text - Code [1pt]\n",
    "5. Exercise - Analysis POS-tagging [1pt]\n",
    "6. Exercise - Reconstruct Missing POS Tags [2pts]\n",
    "7. Exercise - Rank Fluent vs Disfluent Sentences - Code [1pt]\n",
    "8. Exercise - Rank Fluent vs Disfluent Sentences - Analysis [1pt]\n",
    "9. Exercise - Semi-supervised Learning [1pts]\n",
    "\n",
    "There are 10 points above.\n",
    "\n",
    "**Use of AI tools**\n",
    "\n",
    "In this course we expect _you_ and your team members to author your work.\n",
    "AI tools are not to be used for drafts, nor code completion, nor revisions, nor as a source of feedback. If you do use AI, it should not contribute to the substance of what you present as your work.  \n",
    "\n",
    "At the end of this notebook you will find a section on _Use of AI tools_. **Make sure to read and complete it**. \n",
    "By submitting a version of this notebook for assessment, you agree with our terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up\n",
    "\n",
    "Take care of dependencies:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tabulate\n",
    "# !pip install --upgrade --force-reinstall  git+https://github.com/probabll/pgmini.git\n",
    "# !pip install scikit-learn\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pgmini\n",
    "# assert pgmini.__version__ == '0.5.0', \"Don't forget to update pgmini and restart your kernel\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmini.m1 import OutcomeSpace\n",
    "from pgmini.m3 import TabularCPDFactor, BayesianNetwork, MarkovNetwork\n",
    "from pgmini.m4 import max_product_variable_elimination, sum_product_variable_elimination, split_factors\n",
    "from pgmini.m5 import gibbs_sampler, draw_initial_assignment\n",
    "from pgmini.util import make_samples_df, df_to_factor, tvd, pgm_to_tabular_factor\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "import pickle\n",
    "import functools\n",
    "from collections import OrderedDict\n",
    "import itertools\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Markov Models (HMMs) as an Example\n",
    "\n",
    "To make the learning process concrete, we'll use **Hidden Markov Models (HMMs)** as our example. HMMs are a special type of Bayesian network that model sequences where we observe one sequence and want to predict another.\n",
    "\n",
    "## What is an HMM?\n",
    "\n",
    "An HMM models the joint distribution of two sequences of the same length:\n",
    "- **Observed sequence** $X = (x_1, x_2, \\ldots, x_n)$: what we can see\n",
    "- **Hidden sequence** $Y = (y_1, y_2, \\ldots, y_n)$: what we want to predict\n",
    "\n",
    "For example, in part-of-speech (POS) tagging:\n",
    "- $X$ is a sequence of words: \"the cat sat\"\n",
    "- $Y$ is a sequence of POS tags: \"DET NOUN VERB\"\n",
    "\n",
    "The HMM makes two key assumptions:\n",
    "1. **Markov assumption**: Each hidden state $H_i$ depends only on the previous hidden state $H_{i-1}$\n",
    "2. **Independence assumption**: Each observation $O_i$ depends only on the corresponding hidden state $H_i$\n",
    "\n",
    "The joint probability is:\n",
    "$$P(X=x, Y=y) = \\prod_{i=1}^n P(H_i=y_i|H_{i-1}=y_{i-1}) P(O_i=x_i|H_i=y_i)$$\n",
    "\n",
    "Where $n = |x|$ is the length of the sequence. We assume the parent of the first hidden variable $H_1$ is always some fixed value such as $H_0=h^0$.\n",
    "\n",
    "## Parameter Sharing\n",
    "\n",
    "HMMs use **parameter sharing**: all transitions $P(H_i|H_{i-1})$ share the same parameters (a transition table), and all emissions $P(O_i|H_i)$ share the same parameters (an emission table). This makes learning more efficient and allows the model to generalize to sequences of any length.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing an HMM\n",
    "\n",
    "Let's see how to construct an HMM as a Bayesian network. \n",
    "\n",
    "To construct HMMs we will use templates. These templates are conditional probability tables that we repeat for the amount of steps in a HMM (this is parameter sharing!).\n",
    "\n",
    "The function below builds a BN for a sequence of a given length using these templates:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_hmm(hidden_rv: str, obs_rv: str, outcome_spaces: dict, h_bos: str, templates: dict, length: int):\n",
    "    \"\"\"\n",
    "    Return a BN representation of the HMM distribution over sequence pairs of a certain length.\n",
    "    \n",
    "    hidden_rv: name of the hidden rv H (e.g, H for 'hidden')\n",
    "    obs_rv: name of the observed rv O (e.g., O for 'observed')\n",
    "    outcome_spaces: dict mapping an rv (hidden or obs) to its OutcomeSpace object\n",
    "    h_bos: the outcome in Val(H) which is to be used to denote that a hidden sequence has started\n",
    "    templates: dict mapping an rv (hidden or obs) to its template tabular CPD\n",
    "    length: the length of the sequence pair\n",
    "    \"\"\"\n",
    "    assert 0 < length < 1000, \"In this lab we will not be modelling sequences longer than 999 steps.\"\n",
    "    \n",
    "    factors = []\n",
    "    \n",
    "    val_h = outcome_spaces[hidden_rv]\n",
    "    val_o = outcome_spaces[obs_rv]\n",
    "        \n",
    "    # H[001] - first hidden state (depends on BOS)\n",
    "    factors.append(TabularCPDFactor([], f\"{hidden_rv}[001]\", {f\"{hidden_rv}[001]\": val_h}, values=templates[hidden_rv][val_h[h_bos]]))\n",
    "\n",
    "    # H[i] -> H[i+1] - transitions\n",
    "    for j in range(2, length+1):\n",
    "        i = j - 1\n",
    "        hi = f'{hidden_rv}[{i:03d}]'\n",
    "        hj = f'{hidden_rv}[{j:03d}]'\n",
    "        phi_H = TabularCPDFactor([hi], hj, {hi: val_h, hj: val_h}, values=None, from_template=templates[hidden_rv])\n",
    "        factors.append(phi_H)\n",
    "\n",
    "    # H[i] -> O[i] - emissions\n",
    "    for k in range(1, length+1):\n",
    "        hk = f'{hidden_rv}[{k:03d}]' \n",
    "        ok = f'{obs_rv}[{k:03d}]'\n",
    "        phi_O = TabularCPDFactor([hk], ok, {hk: val_h, ok: val_o}, values=None, from_template=templates[obs_rv])\n",
    "        factors.append(phi_O)\n",
    "\n",
    "    return BayesianNetwork(factors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: A Simple HMM with Two Hidden States\n",
    "\n",
    "Let's build a simple HMM to illustrate how these models work. We'll define a model with two hidden states (0 and 1) and observations that are digits 0-9. Beginning of sentence (BOS) and end of sentence (EOS) are just tools to let us start and finish the chain.\n",
    "\n",
    "**Transition probabilities:**\n",
    "- For the hidden state at time $i=0$, we have:\n",
    "  - $P(H_1 = 0 | H_0 = \\text{BOS}) = 0.5$\n",
    "  - $P(H_1 = 1 | H_0 = \\text{BOS}) = 0.5$\n",
    "- If the hidden state at time $i$ is 0 ($H_i = 0$), then:\n",
    "  - $P(H_{i+1} = 0 | H_i = 0) = 0.8$ (stays in state 0)\n",
    "  - $P(H_{i+1} = 1 | H_i = 0) = 0.1$ (transitions to state 1)\n",
    "  - $P(H_{i+1} = \\text{EOS} | H_i = 0) = 0.1$ (ends the sequence)\n",
    "- Similarly, if $H_i = 1$:\n",
    "  - $P(H_{i+1} = 1 | H_i = 1) = 0.8$ (stays in state 1)\n",
    "  - $P(H_{i+1} = 0 | H_i = 1) = 0.1$ (transitions to state 0)\n",
    "  - $P(H_{i+1} = \\text{EOS} | H_i = 1) = 0.1$ (ends the sequence)\n",
    "\n",
    "**Emission probabilities:**\n",
    "- If the hidden state is 0 ($H_i = 0$), the emission probability $P(O_i | H_i = 0)$ is a uniform distribution over all **even** numbers in 0-9: $\\{0, 2, 4, 6, 8\\}$\n",
    "- If the hidden state is 1 ($H_i = 1$), the emission probability $P(O_i | H_i = 1)$ is a uniform distribution over all **odd** numbers in 0-9: $\\{1, 3, 5, 7, 9\\}$\n",
    "\n",
    "Note that the model requires us to define conditional distibutions for all variables (both transitions and emissions), so we will add '-BOS-' and '-EOS-' as emissions for '-BOS-' and '-EOS-' respectively. Also, if '-EOS-' is sampled as the outcome of the hidden state, all next outcomes will also be '-EOS-'.\n",
    "\n",
    "Let's generate this model and verify that it works with sampling.\n",
    "\n",
    "First we start with building the conditional probability tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define outcome spaces for the simple HMM example\n",
    "simple_outcome_spaces = {\n",
    "    'H': OutcomeSpace(['-BOS-', '0', '1', '-EOS-']),  # Hidden states: BOS, 0, 1, EOS\n",
    "    'O': OutcomeSpace(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '-BOS-', '-EOS-']),  # Observations: digits 0-9\n",
    "}\n",
    "\n",
    "# Initialize transition probability table\n",
    "transitions = np.zeros((4, 4))\n",
    "transitions[0, :] = np.array([[0, .5, .5, 0]]) # Transition from BOS to 0 or 1\n",
    "transitions[1, :] = np.array([[0, .8, .1, .1]]) # Transition from 0 to 0, 1, EOS\n",
    "transitions[2, :] = np.array([[0, .1, .8, .1]]) # Transition from 1 to 0, 1, EOS\n",
    "transitions[3, :] = np.array([[0, 0, 0, 1]]) # EOS is absorbing\n",
    "\n",
    "# Initialize emission probability table\n",
    "emissions = np.zeros((4, 12))\n",
    "emissions[0, -2] = 1.0 # BOS emits BOS\n",
    "emissions[1, :] = np.array([[.2, 0, .2, 0, .2, 0, .2, 0, .2, 0, 0, 0]]) # State 0 emits even numbers uniformly\n",
    "emissions[2, :] = np.array([[0, .2, 0, .2, 0, .2, 0, .2, 0, .2, 0, 0]]) # State 1 emits odd numbers uniformly\n",
    "emissions[3, -1] = 1.0 # EOS emits EOS\n",
    "\n",
    "# Create template factors\n",
    "simple_templates = {\n",
    "    'H': transitions,\n",
    "    'O': emissions\n",
    "}\n",
    "\n",
    "# Verify that rows sum to 1 (each row defines all possible outcomes for a given condition)\n",
    "assert np.sum(emissions, axis=-1).all() == 1.0\n",
    "assert np.sum(transitions, axis=-1).all() == 1.0\n",
    "\n",
    "print(\"Transition probabilities (rows: from state, cols: to state):\")\n",
    "print(f\"Hidden states: \\n[-BOS-, 0, 1, -EOS-]: \\n{transitions}\")\n",
    "print(\"\\nEmission probabilities (rows: hidden state, cols: observed digit):\")\n",
    "print(f\"Observed digits: \\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9,-BOS-, -EOS-]: \\n{emissions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Sampling\n",
    "\n",
    "Now that we have defined a model, we need a way to sample from it. As we have a BN without evidence we can just use forward sampling. \n",
    "\n",
    "Make sure to loop over the graph in topologiical order!\n",
    "\n",
    "\n",
    " **EXERCISE - Implement Forward Sampling [1pt]**\n",
    "Complete the function `forward_sampling()` and check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_sampling(bn: BayesianNetwork, rng=np.random.default_rng(42)):\n",
    "    \"\"\"\n",
    "    Forward sampling from a BN\n",
    "    Loop over the variables in the BN in topological order, \n",
    "    sampling the outcome for each variable conditioned on its parents.\n",
    "\n",
    "    :param bn: a BayesianNetwork object\n",
    "    :param rng: a random number generator\n",
    "    :return: a joint assignment of the variables in the BN\n",
    "    \"\"\"\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "    raise NotImplementedError(\"You need to implement this!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define some helper functions to visualize the joint assignments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tostring(seq_pair, vertical=True, headers=['Observed', 'Hidden']):\n",
    "    \"\"\"\n",
    "    :param seq_pair: a sequence of pairs for (O, H) outcomes.\n",
    "    :param vertical: use True for vertical printing with tabulate.\n",
    "    :return: a string representing the sequence of pairs.\n",
    "    \"\"\"\n",
    "    if vertical:\n",
    "        return tabulate(list(seq_pair), headers=headers)\n",
    "    else:\n",
    "        return ' '.join(f'{o}/{h}' for o, h in seq_pair)\n",
    "\n",
    "def tostring2(obs_seq, hid_seq, vertical=True, headers=['Observed', 'Hidden']):\n",
    "    \"\"\"\n",
    "    :param obs_seq: a sequence of observations\n",
    "    :param hid_seq: a corresponding sequence of hidden labels\n",
    "        they must have the same length\n",
    "    :param vertical: use True for vertical printing with tabulate.\n",
    "    :return: a string representing the sequence of pairs.\n",
    "    \"\"\"\n",
    "    assert len(obs_seq) == len(hid_seq), \"I need the same number of elements in both sequences\"\n",
    "    return tostring(zip(obs_seq, hid_seq), vertical=vertical, headers=headers)\n",
    "\n",
    "def assignment_tostring(assignment, obs_rv, hidden_rv, vertical=True):    \n",
    "    return tostring2([assignment[rv] for rv in sorted(assignment.keys()) if rv.startswith(obs_rv)], \n",
    "                     [assignment[rv] for rv in sorted(assignment.keys()) if rv.startswith(hidden_rv)], \n",
    "                     vertical=vertical)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the BN\n",
    "# We will construct BNs up to length 10\n",
    "simple_bn = construct_hmm('H', 'O', simple_outcome_spaces, '-BOS-', simple_templates, 10)\n",
    "# Sample a few sequences\n",
    "print(\"Sampling sequences from the simple HMM:\")\n",
    "rng = np.random.default_rng(42)\n",
    "for i in range(3):\n",
    "    sample = forward_sampling(simple_bn, rng=rng)   \n",
    "    for rv, observed in sample.copy().items():\n",
    "        # Lets remove the -EOS- tokens\n",
    "        if observed == '-EOS-':\n",
    "            sample.pop(rv)\n",
    "            \n",
    "    # Use assignment_tostring to display the sample\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(assignment_tostring(sample, 'O', 'H'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training: Maximum Likelihood Estimation (for Discrete PGMs)\n",
    "\n",
    "Now that we know what HMMs are and how we can sample from them, the next exercises will be about how we can learn the parameters of an HMM.\n",
    "\n",
    "## A Brief Reminder: How to Calculate MLE\n",
    "\n",
    "Given an outcome for an input variable ($H_{i}=y_m$):\n",
    "- Count the number of outcomes of each output variable $\\#(H_{i+1}=y_m|H_{i}=y_n)$ or $\\#(X_i=x_m|H_{i}=y_n)$ \n",
    "- Divide by the total count\n",
    "\n",
    "Where $X$ and $Y$ are the outcome spaces and $y_m, y_n \\in Y$ and $x_m \\in X$ are outcomes.\n",
    "\n",
    "Do this for both transitions ($P(H_{t+1}|H_{t})$) and emissions ($P(X_{t}|H_{t})$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE - Understanding MLE [0pts] (but still good to do)**\n",
    "\n",
    "Before implementing MLE, let's understand what we're counting.\n",
    "\n",
    "**Question**: In an HMM, if we have training data with sequences like:\n",
    "- (words: \"the cat\", tags: \"DET NOUN\")\n",
    "- (words: \"a dog\", tags: \"DET NOUN\")\n",
    "\n",
    "In this case, the tags are the outcomes of the hidden variables and the words are the observed outcomes.\n",
    "\n",
    "What transition counts would we observe? What emission counts?\n",
    "\n",
    "**ANSWER:**\n",
    "\n",
    "- Transition counts: DETâ†’NOUN appears 2 times\n",
    "- Emission counts: (DET, \"the\") appears 1 time, (DET, \"a\") appears 1 time, (NOUN, \"cat\") appears 1 time, (NOUN, \"dog\") appears 1 time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE - Implement MLE [2 points]**\n",
    "\n",
    "Finish the function `estimate_parameters_hmm()` to get CPD tables that represent the Maximum Likelihood Estimation given some dataset of pairs.\n",
    "\n",
    "To count transitions, we define a helper function to iterate over consecutive pairs in sequences (you might find it useful):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_bigrams(seq):\n",
    "    \"\"\"Iterate over consecutive pairs in a sequence\"\"\"\n",
    "    a, b = itertools.tee(seq, 2)\n",
    "    next(b, None)    \n",
    "    return zip(a, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_parameters_hmm(pairs, hidden_rv, obs_rv, outcome_spaces):\n",
    "    \"\"\"\n",
    "    Estimate HMM parameters using MLE.\n",
    "    - pairs: training data\n",
    "    - hidden_rv: name of hidden rv\n",
    "    - obs_rv: name of observed rv\n",
    "    outcome_spaces: dict mapping rv name to its OutcomeSpace\n",
    "    \n",
    "    Returns a dict with:\n",
    "    - hidden_rv: transition probability table [num_hidden_states, num_hidden_states]\n",
    "    - obs_rv: emission probability table [num_hidden_states, num_obs_states]\n",
    "    \"\"\"\n",
    "    val_h = outcome_spaces[hidden_rv]\n",
    "    val_o = outcome_spaces[obs_rv]\n",
    "    \n",
    "    # Initialize count tables\n",
    "    transitions = np.zeros([len(val_h), len(val_h)])\n",
    "    emissions = np.zeros([len(val_h), len(val_o)])\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    # for x, y in pairs:\n",
    "        \n",
    "\n",
    "    raise NotImplementedError(\"You need to implement this!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing to Ground-Truth Model\n",
    "\n",
    "We can test our MLE implementation by building on the methods from last week:\n",
    "\n",
    "1. Generate data from a known model\n",
    "2. Use that data to train the model \n",
    "3. Compare the trained model to the 'true' model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data\n",
    "\n",
    "Note that we add a '-BOS-' token to each sequence so we can learn to generate correctly when sampling from the '-BOS-' token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate multiple sequences\n",
    "num_samples = 1000\n",
    "generated_pairs = []\n",
    "\n",
    "for sample_idx in range(num_samples):\n",
    "    # Sample a sequence from the model\n",
    "    sample = forward_sampling(simple_bn, rng=rng)\n",
    "\n",
    "    # Add the -BOS- token\n",
    "    sample['H[000]'] = sample['O[000]'] = '-BOS-'\n",
    "\n",
    "    # Extract hidden and observed sequences\n",
    "    hidden_seq = [sample[rv] for rv in sorted([rv for rv in sample.keys() if rv.startswith('H')])]\n",
    "    obs_seq = [sample[rv] for rv in sorted([rv for rv in sample.keys() if rv.startswith('O')])]         \n",
    "    generated_pairs.append((obs_seq, hidden_seq))\n",
    "\n",
    "print(f\"Generated {len(generated_pairs)} sequence pairs\")\n",
    "print(f\"Average sequence length: {np.mean([len(x) for x, y in generated_pairs]):.1f}\\n\")\n",
    "\n",
    "# Show a few examples\n",
    "print(\"Example generated sequences (including -BOS- as the first observation):\")\n",
    "for i in range(3):\n",
    "    obs_seq, hidden_seq = generated_pairs[i]\n",
    "    print(f\"\\nSequence {i+1}:\")\n",
    "    print(obs_seq)\n",
    "    print(hidden_seq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the generated data\n",
    "learned_params = estimate_parameters_hmm(\n",
    "    generated_pairs,\n",
    "    'H',\n",
    "    'O',\n",
    "    simple_outcome_spaces\n",
    ")\n",
    "print(f\"Learned Transition Probabilities:\\n{np.round(learned_params['H'], 2)}\")\n",
    "print(f\"Learned Emission Probabilities:\\n{np.round(learned_params['O'], 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to Ground Truth\n",
    "\n",
    "We can use the TVD method from last week to compare the results. We use our learned parameters to define a new HMM (which is just a chain of CPDs) and compare the TVD between its tables. For this, let's define BNs of length 1 with our new parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_small_hmm = construct_hmm('H', 'O', simple_outcome_spaces, '-BOS-', simple_templates, 1)\n",
    "learned_small_hmm = construct_hmm('H', 'O', simple_outcome_spaces, '-BOS-', learned_params, 1)\n",
    "\n",
    "# Show hmm\n",
    "print(true_small_hmm.dag)\n",
    "true_small_hmm_table = pgm_to_tabular_factor(true_small_hmm)\n",
    "learned_small_hmm_table = pgm_to_tabular_factor(learned_small_hmm)\n",
    "\n",
    "print(f\"TVD between true and learned small HMM: {tvd(true_small_hmm_table, learned_small_hmm_table):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you increase the number of samples, the TVD should get closer to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Data: POS Tagging\n",
    "\n",
    "Now let's train an HMM on real data! We'll use a part-of-speech (POS) tagging dataset where:\n",
    "- **Observed**: sequences of words\n",
    "- **Hidden**: sequences of POS tags (NOUN, VERB, DET, etc.)\n",
    "\n",
    "In part-of-speech (POS) tagging, our observed sequence $X$ is a sequence of words, each random word $W$ is a symbol in the vocabulary $\\text{Val}(W)$ of a language (like English), the hidden sequence $Y$ is a sequence of POS tags (or syntactic word categories), each random tag $T$ is a symbol in a POS tagset $\\text{Val}(T)$, this includes things like NOUN, VERB, DET, PRON, ADVERB, etc.\n",
    "\n",
    "\n",
    "Note that now we do not have a ground-truth model. \n",
    "\n",
    "We do still want to have a model that is close to it, such that it generates well on other data (the validation- and test-set).\n",
    "\n",
    "Let's load the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pos-english.pkl\", \"rb\") as f:\n",
    "    pos_dataset = pickle.load(f)\n",
    "\n",
    "train_size = len(pos_dataset['training_x'])\n",
    "dev_size = len(pos_dataset['dev_x'])\n",
    "print(\"Dataset keys:\", pos_dataset.keys())\n",
    "print(\"\\nNumber of training examples:\", train_size)\n",
    "print(\"Number of dev examples:\", dev_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at a few examples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"A few training examples:\\n\")\n",
    "for n in range(3):    \n",
    "    print(tostring2(pos_dataset['training_x'][n], pos_dataset['training_y'][n]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's set up the outcome spaces and train the model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up outcome spaces\n",
    "pos_outcome_spaces = {\n",
    "    'T': OutcomeSpace(pos_dataset['vocab_t']),\n",
    "    'W': OutcomeSpace(pos_dataset['vocab_w']),\n",
    "}\n",
    "\n",
    "# Train the model using MLE\n",
    "pos_template_factors = estimate_parameters_hmm(\n",
    "    zip(pos_dataset['training_x'], pos_dataset['training_y']),\n",
    "    'T',\n",
    "    'W',\n",
    "    pos_outcome_spaces\n",
    ")\n",
    "\n",
    "# Some quick tests\n",
    "assert pos_template_factors['T'].shape == (14, 14)\n",
    "assert pos_template_factors['W'].shape == (14, 3315)\n",
    "assert np.allclose(pos_template_factors['T'].sum(-1), 1.)\n",
    "assert np.allclose(pos_template_factors['W'].sum(-1), 1.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the example earlier, we can now construct a model and sample from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_bn = construct_hmm('T', 'W', pos_outcome_spaces, '-BOS-', pos_template_factors, 10)\n",
    "sample = forward_sampling(pos_bn, rng=rng)\n",
    "print(assignment_tostring(sample, 'W', 'T'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing: Evaluating the Trained Model\n",
    "\n",
    "Now that we have a trained model, let's evaluate it on validation data. We will need to show the performance of the model in a task that we care about.\n",
    "\n",
    "We will define a couple of task, which you will have to implement, namely:\n",
    "- Inferring POS-tags given a text sequence\n",
    "- Inferring missing tags of a tagged sequence\n",
    "- Comparing fluent versus non-fluent sequences\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max-Product Inference for Prediction and Testing\n",
    "\n",
    "The typical use of an HMM is to perform some inference task _given_ an observed sequence. We develop some helper code for building a BN that is appropriate for conditioning on a given sequence:\n",
    "\n",
    "We'll use max-product inference to predict the most likely tag sequence for an observed word sequence. \n",
    "\n",
    "We have implemented a helper function that defines a BN for texts of any size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_evidence_from_text(obs_seq: list, hidden_rv: str, obs_rv: str, outcome_spaces: dict, h_bos: str, o_eos: str, o_unk: str, templates: dict):\n",
    "    \"\"\"\n",
    "    Construct a BN with the correct number of variables and an evidence assignment.\n",
    "    \n",
    "    Returns:\n",
    "    - bn: BayesianNetwork for the sequence length\n",
    "    - e: OrderedDict with evidence assignments for observed variables\n",
    "    \"\"\"\n",
    "    if obs_seq[-1] != o_eos:  # add o_eos if not there\n",
    "        obs_seq = obs_seq + [o_eos]\n",
    "    \n",
    "    # Construct a BN for the right length\n",
    "    bn = construct_hmm(hidden_rv, obs_rv, outcome_spaces, h_bos, templates, len(obs_seq))\n",
    "    \n",
    "    # Construct an assignment of the observed rvs\n",
    "    e = OrderedDict([(f'{obs_rv}[{i:03d}]', obs if obs in outcome_spaces[obs_rv] else o_unk) \n",
    "                     for i, obs in enumerate(obs_seq, 1)])\n",
    "    return bn, e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE - Inferring POS-tags from text [1pt]**\n",
    "\n",
    "Implement the function `tag_seq_from_text()` below and check the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_seq_from_text(obs_seq: list, hidden_rv: str, obs_rv: str, outcome_spaces: dict, h_bos: str, o_eos: str, o_unk: str, templates: dict):\n",
    "    \"\"\"\n",
    "    Predict the most likely tag sequence for an observed word sequence.\n",
    "    returns:\n",
    "    - pred: dict with predicted tags\n",
    "    - e: OrderedDict with evidence assignments for observed variables\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "\n",
    "    raise NotImplementedError(\"You need to implement this!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [0, 1, 2, 3]:\n",
    "    table = []\n",
    "    pred, e = tag_seq_from_text(pos_dataset['dev_x'][n], \n",
    "                                'T', 'W', \n",
    "                                pos_outcome_spaces, \n",
    "                                pos_dataset['vocab_t.bos'], \n",
    "                                pos_dataset['vocab_w.eos'], \n",
    "                                pos_dataset['vocab_w.unk'], \n",
    "                                pos_template_factors)\n",
    "    for inp, rv_e, rv_p, target in zip(pos_dataset['dev_x'][n], sorted(e.keys()), sorted(pred.keys()), pos_dataset['dev_y'][n]):\n",
    "        table.append([inp, e[rv_e], pred[rv_p], target])\n",
    "        \n",
    "    print(tabulate(table, headers=['Input', 'Obs', 'Pred', 'Gold']))\n",
    "    # print accuracy\n",
    "    correct = sum(1 for i in range(len(pos_dataset['dev_y'][n])) if pos_dataset['dev_y'][n][i] == pred[f'T[{i+1:03d}]'])\n",
    "    print(f\"Accuracy: {correct}/{len(pos_dataset['dev_y'][n])} correct \\n\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Report\n",
    "\n",
    "We have already seen that the model does quite well in terms of classifying the POS-tags correctly.\n",
    "\n",
    "Let's look at how well the POS-tagger performs for each tag individually.\n",
    "\n",
    "We can use sklearn's classification report, which will compare each predicted tag to each gold tag and summarise these comparisons in a number of interesting ways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pairs_for_classification_report(data_x, data_y, pred_assignments, hidden_rv, obs_rv):\n",
    "    \"\"\"\n",
    "    For sklearn's classification report we need a long list of targets and predictions, \n",
    "    so this function collects those by iterating over the labelled data and the predicted assignemnts.\n",
    "\n",
    "    data_x: obs seqs\n",
    "    data_y: hidden seqs\n",
    "    pred_assignments: predicted dicts for the observed sequences\n",
    "    hidden_rv: name of hidden rv\n",
    "    obs_rv: name of observed rv\n",
    "    \"\"\"\n",
    "    h_true = []\n",
    "    h_pred = []\n",
    "    for x, y, pred_assignment in zip(data_x, data_y, pred_assignments):        \n",
    "        x_ = [pred_assignment[rv] for rv in sorted(pred_assignment.keys()) if rv.startswith(obs_rv)]\n",
    "        y_ = [pred_assignment[rv] for rv in sorted(pred_assignment.keys()) if rv.startswith(hidden_rv)]\n",
    "        for inp, obs, pred, target in zip(x, x_, y_, y):            \n",
    "            h_true.append(target)\n",
    "            h_pred.append(pred)\n",
    "    return h_true, h_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we get the predicted assignments\n",
    "dev_assignments = []\n",
    "for obs_seq in pos_dataset['dev_x']:\n",
    "    pred, e = tag_seq_from_text(obs_seq, 'T', 'W', pos_outcome_spaces, pos_dataset['vocab_t.bos'], pos_dataset['vocab_w.eos'], pos_dataset['vocab_w.unk'], pos_template_factors)\n",
    "    dev_assignments.append({**e, **pred})\n",
    "\n",
    "\n",
    "# Then we extract the pairs and report the results\n",
    "h_true, h_pred = extract_pairs_for_classification_report(\n",
    "    pos_dataset['dev_x'], \n",
    "    pos_dataset['dev_y'], \n",
    "    dev_assignments, 'T', 'W')\n",
    "print(classification_report(h_true, h_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE - Analysis POS-tagging [1pt]**\n",
    "\n",
    "Analyze the results you got in both the classification report, as well as the sentence level predictions. What do you observe? Where do we observe mistakes/low scores? Why? Feel free to consult https://universaldependencies.org/u/pos/ .\n",
    "\n",
    "ANSWER: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE - Reconstruct Missing POS Tags [2pts]**\n",
    "\n",
    "In this exercise, you'll take some dev instances and drop some POS tags in the middle, then use inference to reconstruct them. This tests whether the model can use context (both words and surrounding tags) to predict missing tags.\n",
    "\n",
    "Complete the function `reconstruct_missing_tags()` below. The function should:\n",
    "\n",
    "1. Take a sequence pair (words and tags) where some tags are missing (represented as `None`)\n",
    "2. Build an HMM with evidence for the observed words and known tags\n",
    "3. Use max-product inference to predict the missing tags\n",
    "4. Return the reconstructed tag sequence\n",
    "\n",
    "**Hint**: You'll need to condition on both the observed words AND the known tags, then infer the missing tags.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_missing_tags(\n",
    "    words: list,\n",
    "    tags_with_gaps: list,  # List where some elements are None for missing tags\n",
    "    hidden_rv: str,\n",
    "    obs_rv: str,\n",
    "    outcome_spaces: dict,\n",
    "    h_bos: str,\n",
    "    o_eos: str,\n",
    "    o_unk: str,\n",
    "    template_factors: dict\n",
    "):\n",
    "    \"\"\"\n",
    "    Reconstruct missing POS tags using MAP inference.\n",
    "    \n",
    "    Args:\n",
    "        words: List of words (observed sequence)\n",
    "        tags_with_gaps: List of tags where None indicates missing tags\n",
    "        hidden_rv: name of hidden rv (e.g., 'T' for tags)\n",
    "        obs_rv: name of observed rv (e.g., 'W' for words)\n",
    "        outcome_spaces: dict mapping rv name to OutcomeSpace object\n",
    "        h_bos: BOS for hidden sequence\n",
    "        o_eos: EOS for observed sequence\n",
    "        o_unk: UNK symbol for observed sequence\n",
    "        template_factors: dict mapping rv name to table for the HMM's TabularCPDFactor objects\n",
    "        \n",
    "    Returns:\n",
    "        List with missing tags filled in (None values replaced with predicted tags)\n",
    "    \"\"\"\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    raise NotImplementedError(\"You need to implement this!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    test_words = pos_dataset['dev_x'][i]#[:15]  # First 15 words\n",
    "    test_tags = pos_dataset['dev_y'][i]#[:15]   # First 15 tags\n",
    "\n",
    "    # Skip if sentence is too short\n",
    "    if len(test_words) < 3:\n",
    "        continue\n",
    "\n",
    "    # Mask every 2nd tag\n",
    "    masked_tags = [tag if i % 2 != 0 else None \n",
    "                for i, tag in enumerate(test_tags)]\n",
    "\n",
    "    reconstructed = reconstruct_missing_tags(\n",
    "        test_words,\n",
    "        masked_tags,\n",
    "        'T', 'W',\n",
    "        pos_outcome_spaces,\n",
    "        pos_dataset['vocab_t.bos'],\n",
    "        pos_dataset['vocab_w.eos'],\n",
    "        pos_dataset['vocab_w.unk'],\n",
    "        pos_template_factors\n",
    "    )\n",
    "\n",
    "    table = []\n",
    "    for inp, mask, pred, gold in zip(test_words, masked_tags, reconstructed, test_tags):\n",
    "        if mask is not None:\n",
    "            table.append([inp, mask, pred, gold])\n",
    "        else:\n",
    "            table.append([inp, \"___\", pred, gold])\n",
    "        \n",
    "    print(tabulate(table, headers=['Input', 'Mask', 'Pred', 'Gold']))\n",
    "    print()\n",
    "    print(\"Accuracy on masked positions:\")\n",
    "    masked_positions = [i for i, tag in enumerate(masked_tags) if tag is None]\n",
    "    correct = sum(1 for i in masked_positions if test_tags[i] == reconstructed[i])\n",
    "    print(f\"{correct}/{len(masked_positions)} correct \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Marginal Probability Queries and Fluency Ranking\n",
    "\n",
    "**EXERCISE - Rank Fluent vs Disfluent Sentences - Code [1pt]**\n",
    "\n",
    "In this exercise, you'll compute the marginal probability of text sequences (by marginalizing over tag sequences) and use this to rank fluent sentences over disfluent ones.\n",
    "\n",
    "The marginal probability $P(X=x)$ of a word sequence is computed by summing over all possible tag sequences:\n",
    "$$P(X=x) = \\sum_{y} P(X=x, Y=y)$$\n",
    "\n",
    "Complete the function `compute_text_probability()` and use it to rank sentence pairs.\n",
    "\n",
    "__Hint__: You can use the `sum_product_variable_elimination()` function of week 5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_text_probability(\n",
    "    words: list,\n",
    "    hidden_rv: str,\n",
    "    obs_rv: str,\n",
    "    outcome_spaces: dict,\n",
    "    h_bos: str,\n",
    "    o_eos: str,\n",
    "    o_unk: str,\n",
    "    template_factors: dict\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute the marginal probability P(X=x) of a word sequence by marginalizing over all tag sequences.\n",
    "    \n",
    "    Args:\n",
    "        words: List of words\n",
    "        hidden_rv: name of hidden rv (e.g., 'T' for tags)\n",
    "        obs_rv: name of observed rv (e.g., 'W' for words)\n",
    "        outcome_spaces: dict mapping rv name to OutcomeSpace object\n",
    "        h_bos: BOS for hidden sequence\n",
    "        o_eos: EOS for observed sequence\n",
    "        o_unk: UNK symbol for observed sequence\n",
    "        template_factors: dict mapping rv name to table for the HMM's TabularCPDFactor objects\n",
    "        \n",
    "    Returns:\n",
    "        Probability P(X=x)\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    raise NotImplementedError(\"You need to implement this!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create some sentence pairs (fluent vs disfluent) and see if the model can rank them correctly:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentence pairs: (fluent, disfluent)\n",
    "# Disfluencies include: word order errors, missing words, extra words, wrong word choices\n",
    "sentence_pairs = [\n",
    "    (\"Object-subject swap\",\n",
    "        ['the', 'president', 'drives', 'the', 'car'], \n",
    "        ['the', 'car', 'drives', 'the', 'president']),\n",
    "    (\"Displaced article\",\n",
    "        ['the', 'loan', 'may', 'be', 'extended'], \n",
    "        ['loan', 'may', 'be', 'extended', 'the']),\n",
    "    (\"Object-article swap\",\n",
    "        ['the', 'fees', 'would', 'apply', 'to', 'filings'], \n",
    "        ['fees', 'the', 'would', 'apply', 'to', 'filings']),\n",
    "    (\"Displaced verb\",\n",
    "        ['recent', 'industry', 'forecasts', 'for', '1990', 'indicate', 'a', 'slow', 'environment'], \n",
    "        ['recent', 'industry', 'forecasts', 'for', '1990', 'a', 'slow', 'environment', 'indicate']),\n",
    "    (\"Object-verb swap\",\n",
    "        ['this', 'does', 'not', 'sit', 'well', 'with', 'me'], \n",
    "        ['does','this', 'not', 'sit', 'well', 'with', 'me']),\n",
    "    (\"Displaced preposition\",\n",
    "        ['he', 'went', 'to', 'the', 'school'], \n",
    "        ['he', 'went', 'the', 'school', 'to']),\n",
    "    (\"Missing subject\",\n",
    "        ['talcott', 'led', 'a', 'team', 'of', 'researchers'], \n",
    "        ['led', 'a', 'team', 'of', 'researchers']),\n",
    "    (\"Verb-object swap\",\n",
    "        ['the', 'former', 'president', 'raised', 'controversial', 'issues'], \n",
    "        ['the', 'former', 'president', 'controversial', 'issues', 'raised']),\n",
    "    (\"Displaced subject\",\n",
    "        ['the', 'car', 'stopped'], \n",
    "        ['the', 'stopped', 'car']),\n",
    "    (\"Missing verb\",\n",
    "        ['i', 'kept', 'the', 'paper', 'alive'], \n",
    "        ['i', 'the', 'paper', 'alive']),\n",
    "]\n",
    "\n",
    "# Compute probabilities and compare\n",
    "correct_rankings = 0\n",
    "for i, (adjustment, fluent, disfluent) in enumerate(sentence_pairs, 1):\n",
    "    # Compute probabilities\n",
    "    prob_fluent = compute_text_probability(\n",
    "        fluent, 'T', 'W', pos_outcome_spaces,\n",
    "        pos_dataset['vocab_t.bos'], pos_dataset['vocab_w.eos'],\n",
    "        pos_dataset['vocab_w.unk'], pos_template_factors\n",
    "    )\n",
    "    \n",
    "    prob_disfluent = compute_text_probability(\n",
    "        disfluent, 'T', 'W', pos_outcome_spaces,\n",
    "        pos_dataset['vocab_t.bos'], pos_dataset['vocab_w.eos'],\n",
    "        pos_dataset['vocab_w.unk'], pos_template_factors\n",
    "    )\n",
    "    \n",
    "    is_correct = prob_fluent > prob_disfluent\n",
    "    if is_correct:\n",
    "        correct_rankings += 1\n",
    "    \n",
    "    print(f\"\\nPair {i}: {adjustment}\")\n",
    "    print(f\"  Fluent:    {' '.join(fluent)}\")\n",
    "    print(f\"  Disfluent: {' '.join(disfluent)}\")\n",
    "    print(f\"  BF:  {prob_fluent/prob_disfluent:.5f}\")\n",
    "    print(f\"  Ranking:   {'CORRECT' if is_correct else 'WRONG'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"Correct rankings: {correct_rankings}/{len(sentence_pairs)}\")\n",
    "print(f\"Accuracy: {correct_rankings/len(sentence_pairs)*100:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE - Rank Fluent vs Disfluent Sentences - Analysis [1pt]**\n",
    "\n",
    "1. How well does the model distinguish fluent from disfluent sentences? What types of errors does it catch and which does it not catch?\n",
    "\n",
    "ANSWER: ...\n",
    "\n",
    "2. Why might some \"disfluent\" sentences actually have higher probability? \n",
    "\n",
    "ANSWER: ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-Supervised Learning\n",
    "\n",
    "Thus far we have seen that the model performs quite well on most tasks. Let's see what happens if the dataset is much smaller:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We take 1/10 of the training data\n",
    "N = len(pos_dataset['training_x'])//10\n",
    "\n",
    "pos_small_template_factors = estimate_parameters_hmm(\n",
    "    zip(pos_dataset['training_x'][:N], pos_dataset['training_y'][:N]),    \n",
    "    'T',\n",
    "    'W',\n",
    "    pos_outcome_spaces\n",
    ")\n",
    "\n",
    "# We use the same dev set as before\n",
    "pos_small_bn = construct_hmm('T', 'W', pos_outcome_spaces, '-BOS-', pos_small_template_factors, 10)\n",
    "pos_small_dev_assignments = []\n",
    "for obs_seq in pos_dataset['dev_x'][:N]:\n",
    "    pred, e = tag_seq_from_text(obs_seq, 'T', 'W', pos_outcome_spaces, pos_dataset['vocab_t.bos'], pos_dataset['vocab_w.eos'], pos_dataset['vocab_w.unk'], pos_small_template_factors)\n",
    "    pos_small_dev_assignments.append({**e, **pred})\n",
    "\n",
    "h_small_true, h_small_pred = extract_pairs_for_classification_report(\n",
    "    pos_dataset['dev_x'], \n",
    "    pos_dataset['dev_y'], \n",
    "    pos_small_dev_assignments, 'T', 'W')\n",
    "print(classification_report(h_small_true, h_small_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the performance drops! We can improve our model using some combination of labeled and unlabeled data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE - Semi-supervised Learning [1pts]**\n",
    "\n",
    "Implement the semi-supervised learning method below. The method works as follows:\n",
    "\n",
    "1. Estimate the parameters using the labeled data\n",
    "2. Use the parameters to generate labels for the unlabeled data\n",
    "3. Use the combined dataset to estimate the new parameters\n",
    "4. Repeat steps 2 and 3 for a fixed number of times\n",
    "\n",
    "Then use the resulting model to make predictions for the dev set and run the classification report so you can compare before and after. \n",
    "\n",
    "To sample new labels you will need to use Gibbs sampling:\n",
    "- for the initial assignment you can use an arbitrary assignment (as `draw_initial_assignment` produces) or you can use a MAP assignment\n",
    "- you can run the chain for a small number of iterations (e.g., 10)\n",
    "- you can assume the Gibbs chain is mixed even after a small number of iterations (such as 10)\n",
    "- take the last sample in the chain as the sequence that \"completes\" the unlabelled input sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semisupervised_estimation_hmm(\n",
    "    labelled_data, unlabelled_data, dev_labelled, hidden_rv, obs_rv, outcome_spaces, \n",
    "    h_bos, h_eos, o_bos, o_eos, o_unk, \n",
    "    num_iterations, gibbs_num_iterations=10):\n",
    "    \"\"\"\n",
    "    labelled_data: sequence pairs\n",
    "    unlabelled_data: unlabelled sequences\n",
    "    dev_labelled: heldout sequence pairs\n",
    "    hidden_rv: name of hidden rv\n",
    "    obs_rv: name of obs rv\n",
    "    outcome_spaces: dict mapping rv name to OutcomeSpace object\n",
    "    h_bos: BOS for hidden sequence\n",
    "    h_eos: EOS for hidden sequence\n",
    "    o_bos: BOS for observed sequence\n",
    "    o_bos: EOS for observed sequence\n",
    "    o_unk: UNK symbol for observed sequence\n",
    "    num_iterations: for semi-supervised training\n",
    "    gibbs_num_iterations: how many iterations of Gibbs sampling \n",
    "        (we only use the last sample, hence this is basically all burn-in, except for the last sample, which we keep)\n",
    "    \"\"\"\n",
    "    # initialise tables with pseudo counts for smoothing\n",
    "    val_h = outcome_spaces[hidden_rv]\n",
    "    val_o = outcome_spaces[obs_rv]    \n",
    "\n",
    "    labelled_data = list(labelled_data)\n",
    "    dev_labelled = list(dev_labelled)\n",
    "    \n",
    "    parameters = estimate_parameters_hmm(\n",
    "        labelled_data, \n",
    "        hidden_rv=hidden_rv, \n",
    "        obs_rv=obs_rv, \n",
    "        outcome_spaces=outcome_spaces\n",
    "    )\n",
    "\n",
    "    for k in range(num_iterations):  \n",
    "        completed_data = []\n",
    "        # complete unlabelled data\n",
    "        print(f\"{k+1}/{num_iterations} Labelling {len(unlabelled_data)} data points via Gibbs sampling\")\n",
    "        pbar = tqdm(unlabelled_data)\n",
    "        for x in pbar:\n",
    "\n",
    "            ### YOUR CODE HERE\n",
    "\n",
    "            raise NotImplementedError(\"You need to implement this!\")\n",
    "        \n",
    "        parameters = estimate_parameters_hmm(\n",
    "            labelled_data + completed_data, \n",
    "            hidden_rv=hidden_rv, \n",
    "            obs_rv=obs_rv, \n",
    "            outcome_spaces=outcome_spaces\n",
    "        )\n",
    "        \n",
    "        \n",
    "    return parameters\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(pos_dataset['training_x'])//10\n",
    "\n",
    "new_parameters = semisupervised_estimation_hmm(\n",
    "    zip(pos_dataset['training_x'][:N], pos_dataset['training_y'][:N]),    \n",
    "    pos_dataset['training_x'][N:], \n",
    "    dev_labelled=zip(pos_dataset['dev_x'], pos_dataset['dev_y']),\n",
    "    hidden_rv='T', \n",
    "    obs_rv='W', \n",
    "    outcome_spaces=pos_outcome_spaces, \n",
    "    h_bos=pos_dataset['vocab_t.bos'],\n",
    "    h_eos=pos_dataset['vocab_t.eos'],\n",
    "    o_bos=pos_dataset['vocab_w.bos'],\n",
    "    o_eos=pos_dataset['vocab_w.eos'],\n",
    "    o_unk=pos_dataset['vocab_w.unk'],\n",
    "    num_iterations=1,\n",
    "    gibbs_num_iterations=10\n",
    ")\n",
    "\n",
    "new_dev_assignments = []\n",
    "for obs_seq in pos_dataset['dev_x'][:N]:\n",
    "    pred, e = tag_seq_from_text(obs_seq, 'T', 'W', pos_outcome_spaces, pos_dataset['vocab_t.bos'], pos_dataset['vocab_w.eos'], pos_dataset['vocab_w.unk'], new_parameters)\n",
    "    new_dev_assignments.append({**e, **pred})\n",
    "\n",
    "h_true, h_pred = extract_pairs_for_classification_report(\n",
    "    pos_dataset['dev_x'], \n",
    "    pos_dataset['dev_y'], \n",
    "    new_dev_assignments, 'T', 'W')\n",
    "print(classification_report(h_true, h_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We can see that semi-supervised learning greatly improves the performance accuracy even after one step!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this notebook, you learned about parameter learning in PGMs:\n",
    "\n",
    "1. **HMMs**: A concrete example of a PGM that models sequences\n",
    "2. **MLE Training**: Simple count-and-normalize procedure for learning parameters from fully observed data\n",
    "3. **Testing**: Evaluating trained models using inference methods\n",
    "4. **Semi-supervised**: Improve training using unlabeled samples and sampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use of AI Tools\n",
    "\n",
    "By submitting this notebook for grading you testify that:\n",
    "\n",
    "* AI did not draft an earlier version of your work.\n",
    "* You did not use AI-powered code completion.\n",
    "* You did not implement algorithms suggested by an AI tool.\n",
    "* AI did not revise a version of your work.\n",
    "* You did not implement suggestions made by an AI tool.\n",
    "\n",
    "_You_ in the sentences above refers to you and all your team members.\n",
    "_AI_ refers to LM-based tools and assistants (e.g., ChatGPT, Gemini, UvA AI chat, etc.).\n",
    "\n",
    "If you did make use of an AI tool, you should describe the uses you made of it below. Or indicate that no such tool was used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TYPE YOUR STATEMENT HERE**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
